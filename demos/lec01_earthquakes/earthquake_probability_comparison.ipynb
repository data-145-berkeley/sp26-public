{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Estimating Earthquake Probability: Two Approaches\n",
    "\n",
    "**Question**: What's the probability of at least one M $\\ge$ 4.0 earthquake in California in the next week?\n",
    "\n",
    "We'll compare two natural approaches:\n",
    "\n",
    "1. **Empirical CDF**: What fraction of past interarrival times were $\\le$ 7 days?\n",
    "2. **Model-based (MLE)**: Fit an exponential distribution, then compute $P(X \\le 7) = 1 - e^{-\\hat{\\lambda} \\cdot 7}$\n",
    "\n",
    "Both estimators are approximately Gaussian by the CLT, but they have different variances. Which is more precise?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## Part 1: Magnitude $\\ge$ 4.0 Earthquakes\n",
    "\n",
    "### 1.1 Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": "# Load the declustered earthquake data (produced by usgs_gk_ca_mainshocks.ipynb)\nearthquakes = pd.read_csv('data/california_earthquakes_declustered.csv')\nearthquakes['time'] = pd.to_datetime(earthquakes['time'], format='ISO8601')\n\nprint(f\"Total earthquakes in dataset: {len(earthquakes)}\")\nprint(f\"  - Mainshocks: {earthquakes['is_mainshock'].sum()}\")\nprint(f\"  - Dependent: {(~earthquakes['is_mainshock']).sum()}\")\nprint(f\"Date range: {earthquakes['time'].min().date()} to {earthquakes['time'].max().date()}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to mainshocks with M >= 4.0\n",
    "mag_threshold = 4.0\n",
    "mainshocks = earthquakes[(earthquakes['is_mainshock']) & (earthquakes['mag'] >= mag_threshold)].copy()\n",
    "mainshocks = mainshocks.sort_values('time').reset_index(drop=True)\n",
    "\n",
    "print(f\"Mainshocks with M >= {mag_threshold}: {len(mainshocks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute interarrival times (in days)\n",
    "interarrivals = mainshocks['time'].diff().dt.total_seconds() / (60 * 60 * 24)\n",
    "interarrivals = interarrivals.dropna().values\n",
    "\n",
    "print(f\"Number of interarrival times: {len(interarrivals)}\")\n",
    "print(f\"Mean interarrival time: {np.mean(interarrivals):.2f} days\")\n",
    "print(f\"Median interarrival time: {np.median(interarrivals):.2f} days\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "### 1.2 Does the Exponential Model Fit?\n",
    "\n",
    "The exponential distribution is the natural model for waiting times in a Poisson process. If mainshock occurrences follow a Poisson process with rate $\\lambda$, then interarrival times are $\\text{Exponential}(\\lambda)$.\n",
    "\n",
    "Key property: For an exponential distribution, the mean equals the standard deviation. Let's check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_ia = np.mean(interarrivals)\n",
    "std_ia = np.std(interarrivals)\n",
    "\n",
    "print(f\"Mean: {mean_ia:.2f} days\")\n",
    "print(f\"Std:  {std_ia:.2f} days\")\n",
    "print(f\"Ratio (std/mean): {std_ia/mean_ia:.2f}\")\n",
    "print(f\"\\nFor a perfect exponential, this ratio would be 1.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram with exponential fit\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Histogram of data\n",
    "ax.hist(interarrivals, bins=30, density=True, alpha=0.7, color='steelblue', \n",
    "        edgecolor='white', label='Data')\n",
    "\n",
    "# Fitted exponential\n",
    "lambda_hat = 1 / mean_ia\n",
    "x = np.linspace(0, np.percentile(interarrivals, 99), 200)\n",
    "y = lambda_hat * np.exp(-lambda_hat * x)\n",
    "ax.plot(x, y, 'r--', linewidth=2.5, label=f'Exponential fit ($\\\\hat{{\\\\lambda}}$ = {lambda_hat:.3f}/day)')\n",
    "\n",
    "ax.set_xlabel('Interarrival Time (days)', fontsize=12)\n",
    "ax.set_ylabel('Density', fontsize=12)\n",
    "ax.set_title(f'Interarrival Times for M $\\geq$ {mag_threshold} Mainshocks', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.set_xlim(0, None)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"The exponential model appears to fit reasonably well.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "### 1.3 Two Estimators for P(earthquake within 7 days)\n",
    "\n",
    "Now we want to estimate $P(X \\le 7)$ where $X$ is the time until the next earthquake.\n",
    "\n",
    "**Estimator 1: Empirical CDF**\n",
    "$$\\hat{p}_{\\text{ECDF}} = \\frac{1}{n} \\sum_{i=1}^{n} \\mathbf{1}(X_i \\le 7)$$\n",
    "This is just the proportion of observed interarrival times that were 7 days or less.\n",
    "\n",
    "**Estimator 2: MLE-based**\n",
    "$$\\hat{p}_{\\text{MLE}} = 1 - e^{-\\hat{\\lambda} \\cdot 7} \\quad \\text{where} \\quad \\hat{\\lambda} = \\frac{1}{\\bar{X}}$$\n",
    "This fits the exponential model and computes the theoretical probability.\n",
    "\n",
    "Let's compute both from our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 7  # days\n",
    "\n",
    "# Empirical CDF estimate\n",
    "p_ecdf = np.mean(interarrivals <= t)\n",
    "\n",
    "# MLE-based estimate\n",
    "lambda_hat = 1 / np.mean(interarrivals)\n",
    "p_mle = 1 - np.exp(-lambda_hat * t)\n",
    "\n",
    "print(f\"Probability of M >= {mag_threshold} earthquake within {t} days:\\n\")\n",
    "print(f\"  Empirical CDF:  {p_ecdf:.3f}  ({100*p_ecdf:.1f}%)\")\n",
    "print(f\"  MLE-based:      {p_mle:.3f}  ({100*p_mle:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": "<cell_type>markdown</cell_type>The estimates are close, but which one is more *precise*? That is, which has lower sampling variability?\n\n### 1.4 Comparing Sampling Variability via Bootstrap\n\nTo understand the sampling distributions of these estimators, we'll use the bootstrap:\n1. Resample $n = 100$ interarrival times with replacement from our data\n2. Compute both estimates on the bootstrap sample\n3. Repeat many times to see the distribution of each estimator"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": "n_boot_size = 100  # Sample size for each bootstrap sample\nn_bootstrap = 5000\nt = 7\n\nnp.random.seed(42)\n\n# Storage for bootstrap estimates\nboot_ecdf = np.zeros(n_bootstrap)\nboot_mle = np.zeros(n_bootstrap)\n\nfor b in range(n_bootstrap):\n    # Resample with replacement\n    boot_sample = np.random.choice(interarrivals, size=n_boot_size, replace=True)\n    \n    # Empirical CDF estimate\n    boot_ecdf[b] = np.mean(boot_sample <= t)\n    \n    # MLE-based estimate\n    lambda_boot = 1 / np.mean(boot_sample)\n    boot_mle[b] = 1 - np.exp(-lambda_boot * t)\n\nprint(f\"Bootstrap complete: {n_bootstrap} resamples of size {n_boot_size}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": "# Summary statistics\nprint(f\"Bootstrap results for P(X <= {t} days), n = {n_boot_size}:\\n\")\nprint(f\"{'Estimator':<18} {'Mean':>10} {'Std':>10}\")\nprint(\"-\" * 40)\nprint(f\"{'Empirical CDF':<18} {np.mean(boot_ecdf):>10.4f} {np.std(boot_ecdf):>10.4f}\")\nprint(f\"{'MLE-based':<18} {np.mean(boot_mle):>10.4f} {np.std(boot_mle):>10.4f}\")\nprint()\nprint(f\"Std ratio (ECDF / MLE): {np.std(boot_ecdf) / np.std(boot_mle):.2f}\")\nprint(f\"Variance ratio: {np.var(boot_ecdf) / np.var(boot_mle):.2f}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": "# Histogram comparison\nfig, ax = plt.subplots(figsize=(10, 6))\n\n# For ECDF, possible values are k/n. Create bins centered on these values.\n# Bin edges at (k - 0.5)/n for k = 0, 1, ..., n+1\necdf_min, ecdf_max = boot_ecdf.min(), boot_ecdf.max()\nk_min = int(np.floor(ecdf_min * n_boot_size))\nk_max = int(np.ceil(ecdf_max * n_boot_size))\necdf_bin_edges = (np.arange(k_min, k_max + 2) - 0.5) / n_boot_size\n\n# For MLE, use regular bins spanning full range\nmle_min, mle_max = boot_mle.min(), boot_mle.max()\nmle_bins = np.linspace(mle_min, mle_max, 50)\n\nax.hist(boot_ecdf, bins=ecdf_bin_edges, alpha=0.6, color='coral', density=True,\n        label=f'Empirical CDF (std = {np.std(boot_ecdf):.4f})')\nax.hist(boot_mle, bins=mle_bins, alpha=0.6, color='steelblue', density=True,\n        label=f'MLE-based (std = {np.std(boot_mle):.4f})')\n\n# Mark the point estimates\nax.axvline(p_ecdf, color='darkred', linestyle='--', linewidth=2, alpha=0.8)\nax.axvline(p_mle, color='darkblue', linestyle='--', linewidth=2, alpha=0.8)\n\nax.set_xlabel('Estimated Probability', fontsize=12)\nax.set_ylabel('Density', fontsize=12)\nax.set_title(f'Bootstrap Sampling Distributions: P(earthquake within {t} days)\\n'\n             f'M $\\\\geq$ {mag_threshold}, n = {n_boot_size}', fontsize=14, fontweight='bold')\nax.legend(fontsize=11)\n\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "### 1.5 Why is the MLE-based Estimator More Precise?\n",
    "\n",
    "The MLE-based estimator has lower variance because it uses **more information** from each observation.\n",
    "\n",
    "**Empirical CDF**: For each interarrival time $X_i$, it only uses the binary information \"was $X_i \\le 7$ or $X_i > 7$?\" The actual value of $X_i$ is thrown away.\n",
    "\n",
    "**MLE-based**: Uses the actual value of every $X_i$ to estimate $\\lambda$, then transforms to get the probability.\n",
    "\n",
    "**The key insight**: If the exponential model is correct, knowing $\\lambda$ tells you *everything* about the distribution. Estimating $\\lambda$ well (using all the data) lets you estimate any probability or quantile well.\n",
    "\n",
    "**Both are approximately Gaussian** by the CLT:\n",
    "- ECDF: It's a sample mean of binary indicators $\\to$ CLT applies directly\n",
    "- MLE-based: It's a smooth function of $\\bar{X}$ $\\to$ CLT + **delta method**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Magnitude $\\ge$ 5.0 Earthquakes\n",
    "\n",
    "Larger earthquakes are rarer. Let's repeat the analysis for M $\\ge$ 5.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to M >= 5.0 mainshocks\n",
    "mag_threshold_5 = 5.0\n",
    "mainshocks_5 = earthquakes[(earthquakes['is_mainshock']) & (earthquakes['mag'] >= mag_threshold_5)].copy()\n",
    "mainshocks_5 = mainshocks_5.sort_values('time').reset_index(drop=True)\n",
    "\n",
    "# Compute interarrival times\n",
    "interarrivals_5 = mainshocks_5['time'].diff().dt.total_seconds() / (60 * 60 * 24)\n",
    "interarrivals_5 = interarrivals_5.dropna().values\n",
    "\n",
    "print(f\"M >= {mag_threshold_5} mainshocks: {len(mainshocks_5)}\")\n",
    "print(f\"Mean interarrival: {np.mean(interarrivals_5):.1f} days\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram with exponential fit\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "mean_ia_5 = np.mean(interarrivals_5)\n",
    "lambda_hat_5 = 1 / mean_ia_5\n",
    "\n",
    "ax.hist(interarrivals_5, bins=20, density=True, alpha=0.7, color='steelblue', \n",
    "        edgecolor='white', label='Data')\n",
    "\n",
    "x = np.linspace(0, np.percentile(interarrivals_5, 99), 200)\n",
    "y = lambda_hat_5 * np.exp(-lambda_hat_5 * x)\n",
    "ax.plot(x, y, 'r--', linewidth=2.5, label=f'Exponential fit ($\\\\hat{{\\\\lambda}}$ = {lambda_hat_5:.4f}/day)')\n",
    "\n",
    "ax.set_xlabel('Interarrival Time (days)', fontsize=12)\n",
    "ax.set_ylabel('Density', fontsize=12)\n",
    "ax.set_title(f'Interarrival Times for M $\\geq$ {mag_threshold_5} Mainshocks', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.set_xlim(0, None)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point estimates\n",
    "t = 7\n",
    "p_ecdf_5 = np.mean(interarrivals_5 <= t)\n",
    "p_mle_5 = 1 - np.exp(-lambda_hat_5 * t)\n",
    "\n",
    "print(f\"P(M >= {mag_threshold_5} earthquake within {t} days):\\n\")\n",
    "print(f\"  Empirical CDF:  {p_ecdf_5:.3f}  ({100*p_ecdf_5:.1f}%)\")\n",
    "print(f\"  MLE-based:      {p_mle_5:.3f}  ({100*p_mle_5:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrap\n",
    "n_5 = len(interarrivals_5)\n",
    "n_bootstrap = 5000\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "boot_ecdf_5 = np.zeros(n_bootstrap)\n",
    "boot_mle_5 = np.zeros(n_bootstrap)\n",
    "\n",
    "for b in range(n_bootstrap):\n",
    "    boot_sample = np.random.choice(interarrivals_5, size=n_5, replace=True)\n",
    "    boot_ecdf_5[b] = np.mean(boot_sample <= t)\n",
    "    lambda_boot = 1 / np.mean(boot_sample)\n",
    "    boot_mle_5[b] = 1 - np.exp(-lambda_boot * t)\n",
    "\n",
    "print(f\"Bootstrap results (n = {n_5}):\\n\")\n",
    "print(f\"{'Estimator':<18} {'Mean':>10} {'Std':>10}\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"{'Empirical CDF':<18} {np.mean(boot_ecdf_5):>10.4f} {np.std(boot_ecdf_5):>10.4f}\")\n",
    "print(f\"{'MLE-based':<18} {np.mean(boot_mle_5):>10.4f} {np.std(boot_mle_5):>10.4f}\")\n",
    "print()\n",
    "print(f\"Std ratio (ECDF / MLE): {np.std(boot_ecdf_5) / np.std(boot_mle_5):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": "# Histogram comparison\nfig, ax = plt.subplots(figsize=(10, 6))\n\n# For ECDF, possible values are k/n_5. Create bins centered on these values.\necdf_min, ecdf_max = boot_ecdf_5.min(), boot_ecdf_5.max()\nk_min = int(np.floor(ecdf_min * n_5))\nk_max = int(np.ceil(ecdf_max * n_5))\necdf_bin_edges = (np.arange(k_min, k_max + 2) - 0.5) / n_5\n\n# For MLE, use regular bins spanning full range\nmle_min, mle_max = boot_mle_5.min(), boot_mle_5.max()\nmle_bins = np.linspace(mle_min, mle_max, 50)\n\nax.hist(boot_ecdf_5, bins=ecdf_bin_edges, alpha=0.6, color='coral', density=True,\n        label=f'Empirical CDF (std = {np.std(boot_ecdf_5):.4f})')\nax.hist(boot_mle_5, bins=mle_bins, alpha=0.6, color='steelblue', density=True,\n        label=f'MLE-based (std = {np.std(boot_mle_5):.4f})')\n\nax.axvline(p_ecdf_5, color='darkred', linestyle='--', linewidth=2, alpha=0.8)\nax.axvline(p_mle_5, color='darkblue', linestyle='--', linewidth=2, alpha=0.8)\n\nax.set_xlabel('Estimated Probability', fontsize=12)\nax.set_ylabel('Density', fontsize=12)\nax.set_title(f'Bootstrap Sampling Distributions: P(earthquake within {t} days)\\n'\n             f'M $\\\\geq$ {mag_threshold_5}, n = {n_5}', fontsize=14, fontweight='bold')\nax.legend(fontsize=11)\n\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "| Magnitude | Sample Size | ECDF Std | MLE Std | Ratio |\n",
    "|-----------|-------------|----------|---------|-------|\n",
    "| M $\\ge$ 4.0 | larger | lower | lower | ~same |\n",
    "| M $\\ge$ 5.0 | smaller | higher | higher | ~same |\n",
    "\n",
    "**Key takeaways**:\n",
    "1. Both estimators are approximately Gaussian (by CLT)\n",
    "2. The MLE-based estimator has lower variance in both cases\n",
    "3. The efficiency gain is consistent across different magnitude thresholds\n",
    "4. The MLE-based estimator's Gaussianity comes from the **delta method**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}