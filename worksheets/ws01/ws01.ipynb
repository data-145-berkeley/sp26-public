{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data 145 Spring 2026\n",
    "#### Adhikari/Fithian\n",
    "\n",
    "# Worksheet 1 \n",
    "\n",
    "## Homework 1 (due 5 PM Monday 1/26)\n",
    "- Problem 1 (in the notebook; can be done based on Tuesday's lecture)\n",
    "- Problem 2 (on paper)\n",
    "- Problem 5 (on paper)\n",
    "\n",
    "Problems 3 and 4 will be covered in section, along with some warm-ups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. The Power of the MLE and Delta Method\n",
    "\n",
    "In this problem, you'll estimate a quantity related to earthquake frequency and discover how the MLE + delta method dramatically outperforms a naive approach.\n",
    "\n",
    "**Setup:** Let $\\lambda$ be the rate of M $\\geq$ 4.0 mainshock earthquakes in California, measured in earthquakes per day. The number of earthquakes in a (non-leap) year is approximately $\\text{Poisson}(365\\lambda)$.\n",
    "\n",
    "**Estimand:** We want to estimate the **90th percentile** of the annual earthquake count:\n",
    "$$q(\\lambda) = \\text{90th percentile of } \\text{Poisson}(365\\lambda)$$\n",
    "\n",
    "This tells us: \"In 90% of years, we expect at most $q(\\lambda)$ earthquakes.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the earthquake data\n",
    "earthquakes = pd.read_csv('data/california_earthquakes_declustered.csv')\n",
    "earthquakes['time'] = pd.to_datetime(earthquakes['time'], format='ISO8601')\n",
    "\n",
    "# Filter to M >= 4.0 mainshocks\n",
    "mainshocks = earthquakes[(earthquakes['is_mainshock']) & (earthquakes['mag'] >= 4.0)].copy()\n",
    "mainshocks = mainshocks.sort_values('time').reset_index(drop=True)\n",
    "\n",
    "# Compute interarrival times (in days)\n",
    "interarrivals = mainshocks['time'].diff().dt.total_seconds() / (60 * 60 * 24)\n",
    "interarrivals = interarrivals.dropna().values\n",
    "\n",
    "n = len(interarrivals)\n",
    "print(f\"Number of interarrival times: {n}\")\n",
    "print(f\"Mean interarrival time: {np.mean(interarrivals):.2f} days\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**(a) Gaussian Approximation for Poisson Quantiles**\n",
    "\n",
    "For large $\\mu$, the Poisson distribution is approximately Gaussian:\n",
    "$$\\text{Poisson}(\\mu) \\approx N(\\mu, \\mu)$$\n",
    "\n",
    "Using this approximation, derive a formula for the 90th percentile of $\\text{Poisson}(\\mu)$ in terms of $\\mu$.\n",
    "\n",
    "[Use `stats.norm.ppf` to get the 90th percentile of the standard normal distribution.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer:**\n",
    "\n",
    "*[Write your derivation here]*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**(b) MLE for the 90th Percentile**\n",
    "\n",
    "From the interarrival time data, we can estimate $\\lambda$ using the MLE:\n",
    "$$\\hat{\\lambda} = \\frac{1}{\\overline{X}_n}$$\n",
    "\n",
    "\n",
    "- Compute $\\hat{\\lambda}$ from the data.\n",
    "- Using your formula from part Part **a**, compute the MLE-based estimate $\\hat{q} = q(\\hat{\\lambda})$ for the 90th percentile of annual earthquake counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may use as many lines as you need\n",
    "\n",
    "lambda_hat = ...\n",
    "\n",
    "q_hat = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**(c) Delta Method for the Distribution of $\\hat{q}$**\n",
    "\n",
    "We want to predict the sampling distribution of our estimator $\\hat{q} = q(\\hat{\\lambda})$.\n",
    "\n",
    "Recall that for exponential interarrivals with rate $\\lambda$:\n",
    "- $\\overline{X}_n$ has mean $1/\\lambda$ and variance $1/(n\\lambda^2)$\n",
    "- $\\hat{\\lambda} = 1/\\overline{X}_n$\n",
    "\n",
    "By the delta method, $\\hat{\\lambda}$ is approximately normal with:\n",
    "$$\\hat{\\lambda} \\approx N\\left(\\lambda, \\frac{\\lambda^2}{n}\\right)$$\n",
    "\n",
    "Apply the delta method again to find the approximate distribution of $\\hat{q} = q(\\hat{\\lambda})$, in the following steps.\n",
    "\n",
    "- Compute $q'(\\lambda) = \\frac{d}{d\\lambda} q(\\lambda)$\n",
    "- Use the delta method to find $\\text{Var}(\\hat{q})$ in terms of $\\lambda$ and $n$\n",
    "- Plug in $\\hat{\\lambda}$ to get a numerical estimate of $\\text{SD}(\\hat{q})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer:**\n",
    "\n",
    "*[Write your derivation here]*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "...\n",
    "\n",
    "var_q_hat_estimate = ...\n",
    "sd_q_hat_estimate = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**(d) Bootstrap Verification**\n",
    "\n",
    "Check your delta method prediction by bootstrapping the interarrival times in the following steps.\n",
    "\n",
    "\n",
    "- Bootstrap the interarrival times (resample with replacement)\n",
    "- For each bootstrap sample, compute $\\hat{\\lambda}^*$ and then $\\hat{q}^* = q(\\hat{\\lambda}^*)$\n",
    "- Plot the histogram of $\\hat{q}^*$ values and overlay your predicted normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bootstrap = 10000\n",
    "np.random.seed(42)\n",
    "\n",
    "boot_q = np.zeros(n_bootstrap)\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the bootstrap distribution vs delta method prediction\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Bootstrap histogram\n",
    "ax.hist(boot_q, bins=50, density=True, alpha=0.7, color='steelblue', \n",
    "        edgecolor='white', label='Bootstrap distribution')\n",
    "\n",
    "# Delta method normal approximation\n",
    "x_grid = np.linspace(boot_q.min(), boot_q.max(), 200)\n",
    "delta_pdf = stats.norm.pdf(x_grid, q_hat, sd_q_hat_estimate)\n",
    "ax.plot(x_grid, delta_pdf, '--', color='firebrick', linewidth=2.5,\n",
    "        label=f'Delta method: N({q_hat:.1f}, {sd_q_hat_estimate:.2f}²)')\n",
    "\n",
    "ax.axvline(q_hat, color='black', linestyle='--', linewidth=1.5, alpha=0.7,\n",
    "           label=f'MLE estimate: q̂ = {q_hat:.1f}')\n",
    "\n",
    "ax.set_xlabel('Estimated 90th Percentile (earthquakes/year)', fontsize=12)\n",
    "ax.set_ylabel('Density', fontsize=12)\n",
    "ax.set_title('Bootstrap vs Delta Method Prediction for $\\hat{q}$', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"The delta method nailed it!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**e) A Naive Alternative — Sample Quantile of Annual Counts**\n",
    "\n",
    "Instead of using the MLE and delta method, we could try a more direct approach:\n",
    "\n",
    "First count the number of earthquakes in each calendar year. Then take the sample 90th percentile of these annual counts\n",
    "\n",
    "Use the steps below to execute this plan and examine its performance using the bootstrap. \n",
    "- Compute the annual earthquake counts for each year in the data.\n",
    "- Compute the sample 90th percentile.\n",
    "- Bootstrap this estimator by resampling *years* (not interarrivals).\n",
    "= Compare the bootstrap standard deviation to the MLE-based estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count earthquakes per year and compute sample 90th percentile\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrap the sample 90th percentile by resampling years\n",
    "np.random.seed(42)\n",
    "boot_q_naive = np.zeros(n_bootstrap)\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the two bootstrap distributions\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "ax.hist(boot_q, bins=50, density=True, alpha=0.6, color='steelblue',\n",
    "        label=f'MLE + Delta Method (SD = {np.std(boot_q):.2f})')\n",
    "ax.hist(boot_q_naive, bins=30, density=True, alpha=0.6, color='coral',\n",
    "        label=f'Sample 90th Percentile (SD = {np.std(boot_q_naive):.2f})')\n",
    "\n",
    "ax.set_xlabel('Estimated 90th Percentile (earthquakes/year)', fontsize=12)\n",
    "ax.set_ylabel('Density', fontsize=12)\n",
    "ax.set_title('MLE-Based vs Naive Estimator', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nThe MLE-based estimator is MUCH more precise!\")\n",
    "print(f\"Variance ratio ≈ {np.var(boot_q_naive) / np.var(boot_q):.0f}×\")\n",
    "print(f\"\\nThis is equivalent to having {np.var(boot_q_naive) / np.var(boot_q):.0f}× more data!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Summary**\n",
    "\n",
    "**Why is the MLE-based estimator so much better?**\n",
    "\n",
    "1. **The naive approach** uses only ~45 data points (one per year) and estimates a quantile, which is inherently noisy.\n",
    "\n",
    "2. **The MLE-based approach** uses all ~600 interarrival times to estimate $\\lambda$ precisely, then transforms via a known formula.\n",
    "\n",
    "3. **The delta method** lets us predict the variance analytically — no simulation needed!\n",
    "\n",
    "**The moral:** When you have a good parametric model, the MLE + delta method can dramatically outperform nonparametric approaches. The model lets you \"borrow strength\" from all of your data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Convergence in Quadratic Mean\n",
    "\n",
    "Let $X_1, X_2, \\ldots$ and $X$ be defined on the same space. We say that $X_n$ *converges in quadratic mean* to $X$ if $E((X_n - X)^2) \\to 0$ as $n \\to \\infty$. In other words, convergence in quadratic mean is the same as the mean squared difference going to $0$.\n",
    "\n",
    "Show that convergence in quadratic mean implies convergence in probability. It's a good idea to start by writing the event $|X_n - X| > \\epsilon$ in terms of $(X_n - X)^2$. Then review the main ideas used to prove [Chebyshev's inequality](https://data140.org/textbook/content/chapter-12/bounds/#chebyshevs-inequality) and [Chernoff's bound](https://data140.org/textbook/content/chapter-19/chernoff-bound/#exponential-bounds-on-tails)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Convergence, or not\n",
    "Let $U$ be uniform on the interval $(0, 1)$. For $n \\ge 1$ define $X_n = nI(U \\leq 1/n)$.\n",
    "\n",
    "**(a)** What is the distribution of $X_n$? Sketch the cdf of $X_n$.\n",
    "\n",
    "**(b)** Does $X_n$ converge in distribution? If so, to what? Justify your answer, and remember that to establish convergence in distribution you need to show convergence of the cdf sequence at all continuity points of the limit cdf.\n",
    "\n",
    "**(c)** Does $X_n$ converge in probability? If so, to what? Justify your answer.\n",
    "\n",
    "**(d)** Does the numerical sequence $E(X_n)$ converge? If so, to what?\n",
    "\n",
    "**(e)** Does convergence in probability imply convergence in quadratic mean? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Sums and Convergence in Probability\n",
    "\n",
    "Suppose $X_n \\stackrel{P}{\\to} X$ and $Y_n \\stackrel{P}{\\to} Y$. Show that $X_n + Y_n \\stackrel{P}{\\to} X+Y$, in the following steps.\n",
    "\n",
    "**(a)** Find an upper bound for $\\vert X_n + Y_n - (X+Y) \\vert$ using $\\vert X_n - X \\vert$ and $\\vert Y_n - Y \\vert$.\n",
    "\n",
    "**(b)** Fix $\\epsilon > 0$. For the event $\\vert X_n + Y_n - (X+Y) \\vert > \\epsilon$ to occur, what must $\\vert X_n - X \\vert$ and $\\vert Y_n - Y \\vert$ do? Answer this by filling in the blank with a phrase: \"At least one of them must be $\\underline{~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~}$\".\n",
    "\n",
    "**(c)** Complete the argument."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Standardizing the Sample Mean\n",
    "\n",
    "Let $X_1, X_2, \\ldots$ be i.i.d. with mean $\\mu$ and variance $\\sigma^2$. Let $\\bar{X}_n = \\frac{1}{n}\\sum_{i=1}^n X_i$. The CLT says that the sequence $\\displaystyle{\\frac{\\bar{X}_n - \\mu}{\\sigma/\\sqrt{n}}}$ converges in distribution to standard normal. This allows us to use $\\bar{X}_n \\pm 2\\sigma/\\sqrt{n}$ as an approximate 95% confidence interval for $\\mu$.\n",
    "\n",
    "In practice, we typically don't know $\\sigma$. In the prerequisite classes we told you that it's fine to substitute the unknown $\\sigma$ with the SD of the sample. In this exercise you'll see why that's OK. \n",
    "\n",
    "**(a) Preliminary fact about any list of numbers:** For numbers $x_1, x_2, \\ldots, x_n$, let $\\bar{x} = \\frac{1}{n}\\sum_{i=1}^n x_i$. Show that\n",
    "\n",
    "$$\n",
    "\\frac{1}{n} \\sum_{i=1}^n (x_i - \\bar{x})^2 ~ = ~ \\frac{1}{n} \\sum_{i=1}^n x_i^2 ~ - ~ \\bar{x}^2\n",
    "$$\n",
    "\n",
    "Only do algebra if you must. It's better to identify the appropriate application of the familiar random variable fact $Var(X) = E(X^2) - (E(X))^2$.\n",
    "\n",
    "**(b) Convergence of the plug-in estimator of $\\sigma^2$:** Let $\\hat{\\sigma}_n^2 = \\frac{1}{n}\\sum_{i=1}^n (X_i - \\bar{X_n})^2$ be the mean squared deviation from the sample average. This is the natural \"plug in\" estimator of the underlying variance $\\sigma^2$.\n",
    "\n",
    "Show that $\\hat{\\sigma}_n^2$ converges in probability to a constant, and identify the constant. You'll need Part **a** and Problem 4 as well as facts from lecture.\n",
    "\n",
    "**(c) Using the plug-in estimator of $\\sigma^2$:** Typically, you don't know $\\sigma^2$. But you can always calculate $\\hat{\\sigma}^2$. Does $\\displaystyle{\\frac{\\bar{X}_n - \\mu}{\\hat{\\sigma}_n/\\sqrt{n}}}$ converge in distribution? If so, to what? Justify your answer carefully, and then use it to provide a formula for an approximate 95\\% confidence interval for $\\mu$ when $n$ is large. \n",
    "\n",
    "**(d) Using the \"sample variance\" instead:** The less natural estimator $S_n^2 = \\frac{1}{n-1}\\sum_{i=1}^n (X_i - \\bar{X_n})^2 = \\frac{n}{n-1}\\hat{\\sigma}_n^2$ is called the *sample variance.* In your probabiilty class you showed that $S_n^2$ is an unbiased estimator of $\\sigma^2$. Does $\\displaystyle{\\frac{\\bar{X}_n - \\mu}{S_n/\\sqrt{n}}}$ converge in distribution? If so, to what? Justify your answer carefully, and then use it to provide a formula for an approximate 95\\% confidence interval for $\\mu$ when $n$ is large.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
